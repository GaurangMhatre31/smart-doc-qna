{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47cd77b9-a357-4d93-b0ef-6b5b8dbb8ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Function to install packages programmatically\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install the necessary packages\n",
    "required_packages = ['pdfplumber', 'python-docx', 'Pillow', 'pyttsx3', 'SpeechRecognition', 'transformers']\n",
    "\n",
    "for package in required_packages:\n",
    "    install(package)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f3ee2f-116a-471d-ba50-b2fee8d16611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Function for text-to-speech\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba6864b-81e3-4f40-bcbd-61b071c06d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from docx import Document\n",
    "from PIL import Image\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = ''\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Function to extract text from Word file\n",
    "def extract_text_from_word(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "# Function to extract text from an image (Placeholder for OCR integration)\n",
    "def extract_text_from_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image.show()  # Just opens the image for now\n",
    "        return \"Image opened successfully. (Implement OCR here for text extraction)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error loading image: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ac72f9-9b2e-4f73-9e9b-2c8f17e37093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Function to recognize speech and return it as text\n",
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone()\n",
    "    with mic as source:\n",
    "        print(\"Listening for your voice...\")\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(\"You said:\", text)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Sorry, I could not understand what you said.\"\n",
    "    except sr.RequestError:\n",
    "        return \"Could not request results from the speech recognition service.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0831bc0-bf2b-41d0-a410-8c7187917d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the question-answering model\n",
    "def initialize_qa_model():\n",
    "    print(\"Loading the QA model...\")\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "    print(\"Model loaded successfully.\")\n",
    "    return qa_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b772be75-de88-440c-85bc-bc70321e694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get answer based on extracted text\n",
    "def get_answer(qa_pipeline, question, context):\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    return result['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13816cb7-b334-4a92-a9c7-1382d231c283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the QA model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GAURANG MHATRE\\Music\\New folder\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the file path (PDF or Word document):  C:\\Users\\GAURANG MHATRE\\Downloads\\All-about-plants-7-320.webp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid file type. Please upload a PDF or Word file.\n"
     ]
    }
   ],
   "source": [
    "# Main function to read PDF or Word files and ask questions\n",
    "def main():\n",
    "    # Initialize the QA model\n",
    "    qa_pipeline = initialize_qa_model()\n",
    "\n",
    "    # Get the file path from the user\n",
    "    file_path = input(\"Please enter the file path (PDF or Word document): \")\n",
    "\n",
    "    # Check the file extension to determine how to read it\n",
    "    context = \"\"\n",
    "    if file_path.lower().endswith('.pdf'):\n",
    "        context = extract_text_from_pdf(file_path)\n",
    "    elif file_path.lower().endswith('.docx'):\n",
    "        context = extract_text_from_word(file_path)\n",
    "    else:\n",
    "        print(\"Invalid file type. Please upload a PDF or Word file.\")\n",
    "        return\n",
    "\n",
    "    if not context.strip():\n",
    "        print(\"No text was extracted from the file.\")\n",
    "        return\n",
    "\n",
    "    # Loop for user questions\n",
    "    while True:\n",
    "        question = input(\"\\nAsk a question (or type 'exit' to quit): \")\n",
    "        if question.lower() == 'exit':\n",
    "            print(\"Exiting question loop.\")\n",
    "            break\n",
    "\n",
    "        # Get the answer from the model\n",
    "        answer = get_answer(qa_pipeline, question, context)\n",
    "        if answer:\n",
    "            print(f\"Answer: {answer}\")\n",
    "            speak(answer)  # Speak the answer\n",
    "        else:\n",
    "            print(\"No answer found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459bf15-3d0a-49b6-b261-20def1b390bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
